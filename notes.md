## Addition
- rope scaling
- 

# Weaker version
- train on composed task, and test on LG for individual tasks

## Smaller tasks
- 3SUM and parity
- Duplicate and reverse
- rotate and reverse
- sort
- mode?

## COT
- Automata format
  - kinda works really well?

## Other 
- Does LG scale with compute
- curriculum learning
- backtrack token
- top p/non greedy decoding/supress eos
- pad to fixed length
